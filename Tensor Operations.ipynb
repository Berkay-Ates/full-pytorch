{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction \n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition - Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([1,2,3])\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 10., 10.])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = my_tensor + 10\n",
    "print(my_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1205, 0.2410, 0.3614])\n"
     ]
    }
   ],
   "source": [
    "my_tensor =  my_tensor-10\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication and Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([1,2,3])\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8446744073709551616,  1553255926290448384, -6893488147419103232])\n"
     ]
    }
   ],
   "source": [
    "my_tensor= my_tensor*10\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmy_tensor\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "my_tensor*torch.tensor([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 10.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = my_tensor/8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2048, 1.2048, 1.2048])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyThorch In Build Functions for basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8193, 4.8193, 4.8193])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.mul_(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8193, 4.8193, 4.8193])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8193, 2.4096, 2.4096])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.div_(torch.tensor([1,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8193, 2.4096, 2.4096])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "- Two main ways of matrix multiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element-wise multiplication \n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "- There are 2 main rules that performing matrix multiplication needs to satisfy:\n",
    "\n",
    "1. The **inner dimensions** must match\n",
    "    * (3,2) @ (2,3) -> This will work \n",
    "    * (2,3) @ (3,2) -> This will also work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [1, 2, 3, 4],\n",
       "        [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix = torch.tensor([[1,2,3,4],[1,2,3,4],[1,2,3,4]])\n",
    "my_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Wise multiplication of my_matris*my_matris:\n",
      " tensor([[ 1,  4,  9, 16],\n",
      "        [ 1,  4,  9, 16],\n",
      "        [ 1,  4,  9, 16]])\n"
     ]
    }
   ],
   "source": [
    "print(f'Element Wise multiplication of my_matris*my_matris:\\n {my_matrix*my_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element Wise multiplication of my_matris*my_matris:\n",
      " tensor([[2, 4, 6, 8],\n",
      "        [2, 4, 6, 8],\n",
      "        [2, 4, 6, 8]])\n"
     ]
    }
   ],
   "source": [
    "my_matrix2 = torch.tensor([2,2,2,2])\n",
    "print(f'Element Wise multiplication of my_matris*my_matris:\\n {my_matrix2*my_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_matrix3 = torch.tensor([2,2,2,2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication of my_matris*my_matris:\n",
      " tensor([20, 20, 20])\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Matrix multiplication of my_matris*my_matris:\\n {torch.matmul(my_matrix,my_matrix3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication of my_matris*my_matris:\n",
      " tensor([20, 20, 20])\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 96.8 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Matrix multiplication of my_matris*my_matris:\\n {(my_matrix@my_matrix3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5595e-03, 4.7798e-01, 1.3597e-01, 5.6996e-01, 1.9012e-01, 4.1230e-01,\n",
       "         8.6397e-01, 6.5388e-01, 9.4629e-01, 9.1107e-01, 1.7843e-01, 7.3691e-01,\n",
       "         3.4453e-01, 4.4846e-01, 7.6120e-01, 8.1665e-01, 4.4127e-01, 8.8027e-01,\n",
       "         7.4929e-01, 3.9152e-01, 6.5561e-01, 4.1813e-01, 7.1430e-01, 5.0994e-01,\n",
       "         5.8877e-02, 3.0868e-01, 3.3858e-01, 8.3696e-01, 1.8103e-01, 4.1320e-01,\n",
       "         9.1544e-01, 3.1769e-01, 8.5079e-01, 3.4101e-01, 1.7904e-01, 9.5577e-01,\n",
       "         1.1342e-01, 3.7661e-01, 3.7590e-01, 7.5780e-01, 9.4195e-01, 2.6444e-01,\n",
       "         4.0563e-01, 3.9204e-01, 1.0056e-02, 5.5370e-01, 1.0780e-01, 7.8804e-02,\n",
       "         4.8733e-01, 4.7721e-02, 6.3191e-01, 5.5488e-01, 7.0018e-01, 2.6130e-01,\n",
       "         8.2360e-01, 8.3643e-01, 9.1655e-02, 1.7610e-01, 4.2128e-01, 5.1772e-01,\n",
       "         2.7036e-01, 4.5681e-01, 2.1080e-01, 8.4236e-01, 9.3917e-02, 8.5203e-01,\n",
       "         7.9222e-01, 9.0821e-01, 1.7571e-02, 6.2414e-01, 4.7250e-01, 7.3152e-01,\n",
       "         6.7569e-01, 9.9173e-01, 9.7747e-01, 6.9144e-01, 5.5864e-01, 5.6944e-01,\n",
       "         7.5144e-01, 3.3775e-01, 7.4179e-02, 1.1602e-01, 5.3178e-01, 5.1176e-02,\n",
       "         6.8961e-01, 2.0373e-01, 9.2948e-01, 8.9176e-01, 2.9542e-01, 3.9994e-01,\n",
       "         6.5396e-01, 2.9996e-01, 1.6874e-01, 9.3460e-05, 8.2023e-01, 6.2680e-01,\n",
       "         7.1925e-02, 1.5042e-01, 1.4244e-01, 4.2603e-01],\n",
       "        [8.6378e-01, 9.3866e-01, 3.1829e-01, 2.5505e-01, 9.9400e-01, 6.2089e-01,\n",
       "         8.3433e-01, 2.0810e-01, 2.8706e-01, 5.4898e-01, 5.3676e-01, 2.1704e-01,\n",
       "         1.9522e-01, 7.9774e-01, 5.6902e-01, 3.6604e-01, 1.3891e-01, 4.7049e-01,\n",
       "         4.8987e-01, 4.5250e-01, 3.6419e-01, 1.5279e-01, 4.7446e-01, 4.9440e-01,\n",
       "         1.3062e-01, 3.2682e-01, 7.2696e-02, 4.6830e-01, 5.9255e-01, 2.7322e-01,\n",
       "         2.8135e-01, 9.0000e-01, 1.3184e-01, 3.1339e-01, 5.0817e-01, 4.9711e-02,\n",
       "         2.9288e-01, 2.7765e-01, 2.0514e-01, 5.9261e-01, 5.0968e-01, 7.3407e-01,\n",
       "         4.3551e-02, 3.4010e-01, 5.3036e-01, 8.4050e-01, 6.0465e-01, 1.7918e-01,\n",
       "         5.0741e-02, 1.3927e-01, 7.6160e-02, 3.0164e-02, 6.0332e-01, 4.0034e-01,\n",
       "         8.6610e-01, 6.6635e-01, 1.2457e-01, 6.4747e-01, 6.9348e-01, 7.5051e-01,\n",
       "         2.9480e-02, 4.9515e-01, 4.4218e-01, 3.1310e-01, 5.9891e-01, 4.6324e-01,\n",
       "         5.5738e-01, 3.1014e-01, 4.1555e-01, 4.1712e-01, 9.4969e-01, 5.2897e-01,\n",
       "         8.6855e-01, 2.6179e-01, 7.1765e-01, 5.1541e-01, 1.3980e-01, 8.0763e-01,\n",
       "         7.1760e-01, 1.9678e-01, 8.7665e-01, 6.6326e-01, 3.6360e-01, 6.7871e-01,\n",
       "         8.6654e-01, 4.6734e-01, 2.4677e-01, 9.1307e-01, 8.1711e-01, 9.5276e-01,\n",
       "         7.7837e-01, 7.3351e-01, 8.3412e-01, 5.4920e-02, 4.6435e-01, 4.8254e-01,\n",
       "         4.3779e-01, 3.8884e-01, 2.4238e-01, 2.4626e-01],\n",
       "        [7.8656e-01, 1.7156e-01, 3.6376e-01, 5.8461e-01, 6.1280e-01, 9.7632e-01,\n",
       "         6.5531e-02, 1.5796e-01, 6.6644e-01, 7.9816e-01, 8.9110e-01, 4.7050e-01,\n",
       "         4.3695e-01, 8.5422e-01, 1.4077e-01, 2.0894e-01, 1.9047e-01, 3.8279e-01,\n",
       "         5.1498e-01, 5.9074e-01, 3.9060e-01, 6.9182e-01, 6.9520e-01, 5.8549e-01,\n",
       "         7.5470e-01, 3.9040e-01, 3.0718e-01, 2.5369e-01, 2.6650e-01, 7.5317e-01,\n",
       "         4.0155e-01, 7.0065e-01, 6.8183e-03, 5.4180e-01, 9.7636e-01, 7.0078e-01,\n",
       "         8.2132e-01, 2.0743e-01, 5.9334e-01, 2.4314e-01, 9.0875e-01, 1.8944e-01,\n",
       "         1.4885e-01, 4.8292e-02, 9.6480e-01, 6.1161e-03, 8.5672e-02, 4.7454e-01,\n",
       "         6.4012e-03, 9.1507e-01, 6.2362e-01, 9.3942e-01, 9.0025e-01, 8.9243e-01,\n",
       "         4.1708e-01, 4.4270e-01, 8.0219e-01, 4.1040e-01, 2.5333e-01, 7.9089e-01,\n",
       "         6.2379e-01, 4.5440e-01, 5.5620e-01, 2.0682e-01, 4.0843e-01, 6.3551e-01,\n",
       "         8.6250e-02, 1.3946e-01, 7.9057e-01, 4.4608e-01, 7.4445e-01, 3.8725e-01,\n",
       "         3.4325e-01, 4.6044e-01, 1.3273e-01, 8.0254e-01, 2.4273e-01, 1.2952e-02,\n",
       "         4.4613e-01, 3.9037e-01, 7.8054e-01, 3.2532e-01, 4.8171e-01, 3.7098e-01,\n",
       "         2.3513e-01, 8.0841e-01, 5.8341e-01, 8.2785e-04, 7.8431e-01, 4.5579e-01,\n",
       "         1.4772e-02, 9.3040e-01, 6.3236e-01, 4.7567e-01, 8.9314e-01, 7.5635e-01,\n",
       "         7.4197e-01, 6.5337e-01, 3.9220e-01, 4.3142e-01],\n",
       "        [8.2906e-01, 3.3454e-01, 1.0501e-01, 3.1499e-01, 5.6565e-01, 2.2598e-01,\n",
       "         9.9253e-01, 1.4178e-01, 5.3129e-01, 3.8407e-01, 1.6902e-01, 6.0958e-01,\n",
       "         7.0796e-01, 6.4603e-01, 7.6744e-01, 8.6446e-01, 2.8701e-01, 1.8106e-03,\n",
       "         5.8013e-01, 9.2765e-01, 4.6632e-01, 4.7487e-01, 8.9969e-01, 3.8635e-01,\n",
       "         5.8733e-02, 2.0393e-01, 4.8367e-01, 7.5055e-01, 1.1222e-01, 7.9364e-02,\n",
       "         4.0335e-01, 3.2293e-01, 2.4851e-01, 8.3257e-01, 7.2178e-01, 2.7051e-01,\n",
       "         5.3157e-01, 8.1439e-01, 2.3060e-01, 2.0116e-01, 2.4498e-01, 4.3071e-01,\n",
       "         1.8371e-01, 4.0813e-02, 4.6531e-01, 2.2753e-01, 8.3092e-01, 8.4860e-01,\n",
       "         3.6873e-01, 4.2721e-01, 7.7269e-01, 3.9094e-01, 6.4074e-01, 8.8037e-01,\n",
       "         4.2342e-01, 9.5077e-01, 3.0077e-01, 9.4800e-02, 3.2520e-01, 3.1419e-03,\n",
       "         7.8962e-01, 8.4746e-01, 8.1685e-01, 5.4460e-02, 3.1920e-01, 6.1031e-01,\n",
       "         6.6592e-01, 5.9939e-01, 1.8544e-01, 7.0988e-01, 7.0880e-01, 5.6030e-01,\n",
       "         8.0861e-01, 4.2954e-01, 2.6232e-01, 5.8946e-01, 6.0508e-01, 3.3187e-01,\n",
       "         8.7373e-01, 5.0248e-01, 2.9201e-01, 4.8147e-01, 4.2653e-01, 3.1145e-01,\n",
       "         3.5941e-01, 4.6362e-01, 5.2983e-01, 3.6684e-01, 4.1884e-01, 4.2592e-01,\n",
       "         5.1013e-01, 4.0045e-02, 3.3227e-01, 3.2398e-01, 3.0508e-01, 8.1428e-01,\n",
       "         3.4085e-01, 6.9100e-01, 6.4907e-01, 6.1216e-01],\n",
       "        [1.9787e-01, 5.3201e-01, 2.0407e-01, 4.5018e-01, 2.7573e-01, 2.7200e-01,\n",
       "         5.6424e-01, 8.3429e-01, 4.8454e-01, 7.8836e-01, 4.0059e-01, 9.1921e-01,\n",
       "         5.6854e-01, 2.7207e-01, 7.0111e-01, 9.7228e-01, 6.8146e-01, 8.9014e-01,\n",
       "         1.4274e-01, 8.9528e-01, 5.5162e-01, 1.9247e-01, 3.6586e-01, 8.9748e-01,\n",
       "         5.0162e-01, 9.7523e-01, 4.0467e-01, 1.0692e-01, 6.5909e-01, 8.2587e-01,\n",
       "         9.9039e-01, 3.4848e-01, 9.6339e-02, 2.2222e-01, 5.0272e-01, 5.3181e-01,\n",
       "         1.9655e-02, 8.3509e-01, 4.0023e-01, 5.5794e-01, 6.4108e-01, 8.4653e-01,\n",
       "         8.4052e-01, 9.5304e-01, 5.2173e-01, 7.1981e-01, 2.7915e-01, 6.9575e-01,\n",
       "         1.5587e-01, 3.6340e-01, 7.8740e-02, 5.0056e-01, 5.4349e-02, 5.5705e-01,\n",
       "         8.3329e-01, 6.9671e-01, 5.2057e-01, 4.5135e-01, 7.0895e-01, 1.9052e-01,\n",
       "         7.6064e-01, 4.0886e-01, 1.6509e-01, 7.6692e-01, 5.3124e-01, 5.8238e-01,\n",
       "         5.9940e-01, 5.0669e-01, 5.5784e-01, 7.5623e-01, 7.6849e-01, 5.7995e-01,\n",
       "         5.3092e-01, 1.9072e-01, 8.6375e-01, 7.4752e-01, 5.2909e-01, 7.9008e-01,\n",
       "         8.6755e-01, 6.4678e-01, 7.8206e-01, 7.9373e-01, 5.5948e-01, 1.2704e-02,\n",
       "         2.4382e-01, 4.6346e-01, 4.7084e-01, 4.1631e-01, 9.9297e-01, 7.4435e-01,\n",
       "         6.9200e-01, 3.1699e-01, 1.9147e-01, 6.0124e-01, 3.4331e-01, 4.9887e-01,\n",
       "         4.3644e-01, 8.3702e-01, 8.7993e-01, 7.6086e-01],\n",
       "        [1.8729e-02, 7.4593e-01, 1.9679e-01, 8.2526e-01, 7.5476e-02, 5.9284e-01,\n",
       "         1.0521e-01, 9.5374e-01, 5.0768e-01, 4.5033e-01, 6.7405e-01, 6.2607e-01,\n",
       "         3.7441e-01, 9.5042e-01, 9.0957e-01, 6.1917e-01, 1.4335e-01, 7.3221e-01,\n",
       "         5.5564e-01, 9.0509e-01, 4.6610e-02, 9.7248e-01, 5.8119e-02, 3.2504e-01,\n",
       "         2.5265e-01, 6.6249e-01, 8.3046e-01, 8.5086e-01, 7.9570e-01, 1.4733e-01,\n",
       "         1.8296e-01, 7.8625e-01, 1.5653e-01, 7.5744e-01, 2.8702e-01, 3.2323e-01,\n",
       "         4.8934e-01, 1.2588e-01, 4.7256e-01, 8.3355e-01, 2.0083e-01, 7.5172e-01,\n",
       "         9.7504e-01, 7.6617e-01, 7.1162e-01, 4.1885e-01, 5.2200e-01, 3.3570e-01,\n",
       "         5.9823e-01, 8.8546e-01, 9.7044e-02, 1.9161e-01, 1.6256e-01, 4.1574e-01,\n",
       "         6.9642e-01, 1.5223e-01, 7.7941e-01, 7.3883e-01, 9.4914e-01, 5.5196e-02,\n",
       "         8.1743e-01, 7.7023e-01, 5.0216e-01, 5.9141e-01, 1.8789e-01, 6.7418e-01,\n",
       "         9.9442e-01, 2.5755e-02, 5.9699e-02, 9.0371e-01, 9.6061e-01, 3.3070e-01,\n",
       "         1.3459e-02, 8.3143e-01, 6.3766e-02, 7.4842e-01, 6.6261e-01, 7.9610e-01,\n",
       "         5.8482e-01, 1.9616e-01, 4.4254e-01, 5.4747e-01, 7.1301e-01, 8.3364e-01,\n",
       "         4.4441e-01, 4.0647e-01, 2.0203e-01, 9.0404e-01, 9.9606e-01, 6.1870e-01,\n",
       "         8.4946e-01, 3.4492e-01, 6.9798e-01, 3.9100e-01, 7.8024e-01, 5.0467e-01,\n",
       "         3.0706e-01, 1.2486e-01, 3.8777e-01, 8.3622e-01],\n",
       "        [3.4041e-01, 4.2697e-01, 2.1667e-01, 8.6017e-01, 3.3903e-01, 5.3225e-01,\n",
       "         1.9625e-01, 9.2805e-01, 8.4265e-02, 4.6406e-01, 6.0814e-01, 7.8073e-01,\n",
       "         4.6897e-01, 6.8707e-01, 4.0618e-01, 6.0588e-01, 6.4401e-01, 6.4870e-01,\n",
       "         5.9183e-01, 4.2816e-01, 8.7629e-01, 5.9485e-01, 3.8442e-01, 6.3443e-04,\n",
       "         1.8401e-01, 4.9417e-01, 4.7631e-01, 5.1054e-01, 5.1249e-01, 1.1456e-03,\n",
       "         4.1100e-01, 1.0151e-01, 2.9681e-01, 2.5076e-01, 7.8663e-01, 8.0696e-01,\n",
       "         5.9066e-01, 7.4778e-01, 4.7887e-01, 4.4747e-01, 4.1236e-01, 4.3172e-01,\n",
       "         9.0310e-01, 7.3626e-01, 4.2812e-01, 9.4500e-01, 6.8733e-01, 8.7128e-01,\n",
       "         8.5231e-01, 2.1267e-01, 7.4221e-01, 1.5380e-01, 9.0499e-01, 5.2793e-01,\n",
       "         7.6803e-01, 4.0729e-01, 6.5248e-02, 2.0693e-01, 8.8574e-01, 2.4201e-01,\n",
       "         5.5915e-01, 1.6858e-01, 3.0004e-01, 5.9534e-02, 7.5244e-02, 2.9633e-01,\n",
       "         5.4738e-01, 7.2586e-01, 5.3248e-01, 2.5946e-01, 8.6234e-02, 3.5874e-01,\n",
       "         6.9594e-01, 1.5200e-01, 6.3756e-01, 1.7337e-01, 8.9381e-02, 8.0641e-01,\n",
       "         2.4701e-01, 3.5598e-01, 4.6861e-01, 6.2527e-02, 4.8921e-01, 8.4942e-01,\n",
       "         3.4498e-01, 4.6912e-01, 6.9305e-01, 4.2637e-01, 8.6763e-01, 7.3862e-01,\n",
       "         3.7203e-01, 1.9405e-01, 6.5233e-01, 8.1974e-01, 8.3684e-01, 8.9703e-01,\n",
       "         8.5263e-01, 9.0849e-01, 5.6650e-01, 9.1765e-01],\n",
       "        [1.3659e-01, 5.9354e-01, 2.1897e-01, 8.8613e-01, 7.6204e-01, 7.2767e-01,\n",
       "         7.1713e-01, 6.7470e-01, 4.0190e-02, 9.6187e-01, 1.7907e-01, 3.6169e-01,\n",
       "         6.4838e-01, 9.5953e-01, 5.6752e-01, 1.0740e-02, 7.4421e-01, 2.9121e-01,\n",
       "         5.9950e-01, 8.3491e-01, 5.2061e-01, 3.0254e-01, 8.3574e-02, 9.6304e-01,\n",
       "         5.5589e-01, 5.4310e-01, 2.8711e-01, 7.7521e-01, 1.6581e-01, 8.0281e-01,\n",
       "         8.5274e-02, 5.0905e-01, 3.9177e-01, 9.5877e-01, 6.7087e-01, 5.2960e-01,\n",
       "         5.8493e-01, 3.6275e-01, 2.1938e-01, 9.8498e-01, 9.7928e-01, 6.3871e-01,\n",
       "         5.7804e-01, 2.0114e-01, 6.2008e-01, 1.1342e-01, 3.6093e-01, 7.1750e-03,\n",
       "         1.6753e-01, 8.2030e-01, 7.2323e-01, 6.5395e-01, 9.8507e-02, 8.4921e-01,\n",
       "         1.5984e-02, 8.7074e-01, 6.8313e-01, 8.7924e-01, 8.7807e-01, 1.3874e-01,\n",
       "         5.8124e-01, 8.1607e-01, 1.8487e-01, 2.8109e-01, 8.4865e-01, 2.2941e-01,\n",
       "         7.9134e-01, 6.5411e-01, 3.2870e-01, 2.3009e-01, 3.3724e-01, 1.0681e-02,\n",
       "         5.0815e-01, 5.8376e-01, 6.9632e-01, 1.9715e-01, 6.5613e-01, 6.6263e-01,\n",
       "         3.5141e-01, 2.2578e-01, 8.9725e-01, 3.4024e-01, 2.6228e-01, 7.3213e-01,\n",
       "         7.4932e-01, 3.3051e-01, 4.1886e-02, 1.5278e-01, 1.8813e-01, 8.3148e-01,\n",
       "         6.7320e-01, 9.9255e-01, 3.3737e-01, 1.8607e-01, 9.1963e-01, 1.8176e-01,\n",
       "         1.0943e-01, 1.4317e-01, 8.5289e-01, 3.1576e-01],\n",
       "        [9.0242e-01, 3.7645e-01, 4.0343e-01, 8.7963e-01, 1.9277e-01, 3.6407e-01,\n",
       "         3.2016e-02, 4.0404e-01, 2.2221e-01, 9.1338e-02, 5.8766e-01, 1.2639e-01,\n",
       "         2.6513e-01, 3.3350e-01, 1.9433e-01, 6.0326e-01, 4.9478e-01, 6.7505e-01,\n",
       "         8.4506e-02, 6.2010e-01, 4.3549e-01, 3.1932e-02, 2.9963e-01, 1.7998e-01,\n",
       "         5.8558e-01, 9.9364e-01, 4.6634e-01, 1.1822e-01, 2.7571e-01, 3.2876e-01,\n",
       "         4.8511e-01, 8.5616e-01, 1.3862e-01, 4.3395e-01, 8.3628e-01, 2.8979e-01,\n",
       "         2.0537e-01, 9.2791e-01, 3.8048e-01, 2.7792e-01, 5.6956e-01, 4.4475e-01,\n",
       "         7.1181e-01, 1.4293e-01, 8.0718e-03, 7.1908e-02, 7.4203e-01, 7.1223e-01,\n",
       "         9.1961e-01, 7.9471e-02, 7.6110e-01, 7.8999e-01, 6.5841e-01, 3.9125e-01,\n",
       "         4.4270e-01, 2.2706e-01, 1.6778e-01, 2.3152e-01, 4.3010e-01, 4.7571e-01,\n",
       "         9.6332e-01, 9.8580e-01, 4.1024e-02, 4.2313e-01, 9.2663e-01, 2.9081e-01,\n",
       "         2.2033e-01, 6.2083e-01, 2.4865e-01, 6.7311e-01, 8.6989e-01, 1.3486e-01,\n",
       "         7.0302e-01, 4.3327e-01, 8.9869e-01, 3.5072e-01, 5.6589e-04, 5.3825e-01,\n",
       "         2.2047e-02, 4.4616e-01, 2.1237e-01, 3.4638e-02, 4.3301e-01, 8.7168e-02,\n",
       "         3.2155e-01, 1.2579e-01, 6.4829e-01, 9.4782e-01, 6.4221e-01, 6.9086e-01,\n",
       "         5.3378e-01, 6.2915e-01, 2.1090e-01, 5.1466e-01, 6.8138e-01, 3.1092e-01,\n",
       "         2.7273e-02, 7.4564e-01, 9.9565e-01, 9.4437e-01],\n",
       "        [3.9087e-01, 8.5384e-01, 8.8504e-01, 1.4652e-01, 5.0427e-01, 6.6125e-01,\n",
       "         2.9473e-01, 3.6922e-01, 8.1449e-01, 9.7701e-01, 3.9376e-01, 3.7762e-01,\n",
       "         7.0907e-01, 1.6861e-01, 6.1491e-01, 3.2874e-01, 5.3456e-01, 6.7873e-01,\n",
       "         4.0142e-01, 4.4592e-01, 6.1849e-02, 1.0209e-01, 9.8482e-01, 2.9669e-02,\n",
       "         9.5888e-02, 2.9865e-01, 6.3571e-02, 9.2393e-01, 9.5656e-01, 7.8218e-01,\n",
       "         5.0716e-01, 6.7454e-01, 2.5230e-01, 6.5690e-01, 3.2553e-01, 2.7677e-01,\n",
       "         1.8654e-01, 9.3656e-01, 1.0135e-01, 6.0263e-01, 3.4368e-01, 4.7669e-01,\n",
       "         2.2955e-01, 2.9284e-01, 2.8809e-01, 7.2908e-01, 8.7423e-01, 1.5773e-01,\n",
       "         4.5623e-01, 5.1836e-01, 1.6043e-01, 1.5129e-01, 3.7529e-02, 3.6572e-01,\n",
       "         2.8090e-01, 1.5760e-02, 6.3012e-01, 9.4589e-01, 1.6803e-01, 2.1544e-01,\n",
       "         7.4861e-01, 3.3171e-01, 8.4924e-01, 9.9090e-01, 3.4022e-01, 3.7954e-01,\n",
       "         2.9716e-01, 4.4213e-01, 2.6797e-01, 6.6464e-01, 1.3066e-01, 6.9976e-01,\n",
       "         7.8048e-01, 8.4379e-01, 8.5329e-01, 5.6956e-01, 1.4271e-02, 9.8882e-01,\n",
       "         2.5671e-01, 4.3630e-01, 7.3088e-01, 4.7017e-01, 9.0200e-01, 3.4866e-01,\n",
       "         4.7496e-01, 9.2986e-01, 1.2565e-02, 6.5627e-01, 2.0283e-01, 1.5350e-01,\n",
       "         6.0705e-02, 7.7360e-02, 1.7318e-01, 6.4617e-01, 7.9615e-01, 8.7983e-01,\n",
       "         5.0520e-01, 6.1615e-01, 7.8270e-01, 9.6016e-01]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication of my_matris*my_matris:\n",
      " torch.Size([10000, 1000])\n",
      "CPU times: total: 7.97 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Matrix multiplication of my_matris*my_matris:\\n {(torch.rand(size=(10000,10000))@torch.rand(size=(10000,1000))).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes for matrix multiplications \n",
    "tensor_A = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "tensor_B = torch.tensor([[7,10],[8,11],[9,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 76, 103],\n",
       "        [100, 136]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A.T,tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_A.T.shape)\n",
    "print(tensor_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A,tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To fix our tensor shape issue, we can manipulate the shape of one of our tensors using a **transpose**\n",
    "\n",
    "A **Transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
